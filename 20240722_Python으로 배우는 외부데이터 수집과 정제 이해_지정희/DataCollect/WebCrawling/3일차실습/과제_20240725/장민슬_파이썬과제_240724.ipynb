{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMLBtK3q76VgYMOVKr82F7v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mC5z4KpNkZcd"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","\n","header = {\n","'User-Agent' : 'Mozilla/5.0',\n","'Referer' : \"https://kin.naver.com/search/list.naver\"}\n","\n","data=[]\n","#max_pages = int(input(\"최대 몇 페이지까지 검색할까요?: \"))\n","# for i in range(1,max_pages+1):  페이지 수가 너무 많아서 로딩하는데 시간이 오래걸려 주석처리\n","for i in range(1,3):\n","    url = f'https://kin.naver.com/search/list.naver?query=%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0&page={i}'\n","    response=requests.get(url,headers=header)\n","    if response.status_code == 200:\n","        result =response.text\n","        soup = BeautifulSoup(result,'html.parser')\n","        items= soup.select('.basic1>li')\n","        #print(items)\n","        for k_in in items:\n","            title=k_in.select_one('dt').text.strip()\n","            #print(title)\n","            link=k_in.select_one('dt > a')['href'].strip()\n","            #print(link)\n","            date=k_in.select_one('.txt_inline').text.strip()\n","            #print(date)\n","            category=k_in.select_one('.txt_g1._nclicks\\\\:kin\\\\.cat2').text.strip()\n","            #print(category)\n","            answer=k_in.select_one('.hit').text.strip()\n","            #print(answer)\n","            #print(title,link,category,answer)\n","            data.append([title,link,date,category,answer])\n","            #print(data)\n","        df = pd.DataFrame(data, columns=['제목', '링크', '날짜', '카테고리', '답변수'])\n","        df.to_excel('k_in.xlsx',index=False)\n","        if soup.select_one('.next,_nclicks\\\\:kin\\\\.next')== None: # 페이지가 없으면 멈춤\n","            break\n","\n","    else:\n","        print(\"실패\",response.status_code)\n",""]}]}